# 컴퓨터 비전과 딥러닝

## 컨볼루션 신경망을 이용한 자연현상 인식
### using CIFAR10

인간은 2차원에서 특징 추출
- 수용장(receptive field)이라는 작은 영역에서 특징을 추출

컨볼루션 신경망(CNN:Convolutional Neural Network)은 인간 시각을 모방
- 딥러닝 성공에 가장 기여한 모델
- 다양한 응용
  - 컴퓨터 비전에서는 분류, 검출, 분할, 추적 등의 문제 해결
  - 비디오 게임 인공지능에서는 화면 장면을 분석
  - 알파고는 19 * 19 바둑판 형세 판단

컨볼루션 신경망
- CNN은 컨볼루션 연산을 하는 신경망 구조
- 고전적ㅇ인 방법에서는 사람이 필터 설계(e.g. 가우시안 스무딩, 소벨 엣지 등)
  - 사람이 설계->적용
  - 인식에 최적이진 않다
  - 매번 데이터셋마다 최적 필터가 달라진다.
 
### CNN의 핵심 아이디어는 '최적의 필터(가중치)를 학습'으로 알아낸다.

인간의 입장에서는 같은 문양일지라도 컴퓨터 입장에서는 불일치하는 픽셀이 많은 경우,
CNN은 픽셀 단위로 보지않고, 영상의 작은 특징 부분을 추출해서 특징끼리 비교한다.

## 컨볼루션 층에서의 영상 특징 추출
문양을 분류하는 convolution layer
특징 추출 : 가중치를 가진 필터를 이용

실제 CNN 모델에서는 위처럼 미리 가중치를 정해주지 않고, 학습하면서 가중치를 계속 업데이트하여 최적의 가중치를 스스로 찾아낸다.

필터와 영상을 컨볼루션하고, 필터와 일치하면 1값을 갖게된다.

필터(마스크)와 영상을 컨볼루션
  - 필터와 일치하지 않는 부분은 1보닫 작은 값을 가지게 된다.

그 결과 3개의 특징맵을 구할 수 있게된다.

## Pooling Layer - 추출된 특징의 압축
윈도우 사이즈를 정한다
-> 윈도우 내 최대 값을 선택한다 = max pooling
-> 윈도우 내 평균 값을 선택한다 = mean pooling
-> 윈도우 내 최소 값을 선택한다 = minimum pooling

7 by 7 사이즈 영상이 4 by 4 사이즈로 작게 되었다.
효과 : 계산 효율을 높이고, 특징의 정확한 위치에 덜 민감하게 된다. (overfitting 방지)
*압축을 했어도 여전히 특징 위치는 유지한다

필터링된 모든 특징맵에 풀링을 적용한다.

## ReLU - 활성화 함수
- 필요성
  - 필터를 통과한 데이터는 덧셈, 곱셈으로만 이루어져 있어서 선형적인 특성을 갖는 상태이다. 이 경우 복잡한 데이터 분류는 힘들다.
  - ReLU와 같은 activation function은 비선형성을 부여해주어 복잡한 데이터도 분류할 수 있도록한다.
  - e.g. 뉴런이 다음 뉴런으로 신호를 보낼 때 입력 신호가 일정 기준 이상이면 보내고, 기준에 달하지 않으면 보내지 않도록 한다.
 
ReLU Layer
일정 값 이상의 정보들만 통과된다. (양수만 통과되고 음수는 0이된다) (=죽은 뉴런이 생긴다. 필요없는 정보는 날리지만 중요한, 값이 큰 부분은 유지한다.)

## 레이어에서 나온 결과는 다음 레이어의 입력으로 들어간다.
## 순서 컨볼루션->ReLU(먼저 필요없는 값을 죽이기 위해)->풀링
더 깊게 레이어를 쌓을 수 있다. 목적에 따라 반복하여 쌓아서 사용한다.

## Fully Connected Layer - 분류를 위한 층
- 추출된 특징들을 평평하게 펼쳐서 다층 신경망에 넣어 이 영상이 무슨 영상인지 분류할 수 있다.
- 다층 신경망을 지나면 문양을 분류하게 된다.

*** 기억할 점!
실제 분류 문제에서는 필터의 가중치를 미리 정해놓고 영상의 특징을 추출하는 것이 아니라, 필터의 가중치를 랜덤하게 두고 오차가 발생하면 오차가 줄어드는 방향으로 학습하여 가중치를 업데이트 하면서 최적의 가중치를 스스로 찾는다.(Back Propagation) (손실함수가 0이되는 방향으로)
